{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMZ0y+DPYXOsXN6QpGNP4KT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dfb46f527ce94159b8c942d0963993cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3fbd6c7c70e4810a8fc92e38e479d0c",
              "IPY_MODEL_9e7eeffe90fa4ca090b7cb253edd9a6d",
              "IPY_MODEL_de9a8f73143042bc83fee982088b790c"
            ],
            "layout": "IPY_MODEL_9cf04bb59d224835abe81441c429cc99"
          }
        },
        "f3fbd6c7c70e4810a8fc92e38e479d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f655166a00e49d79cdfca6ae664859a",
            "placeholder": "​",
            "style": "IPY_MODEL_59b8e8f1de1f41f687268a3f9d24c199",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "9e7eeffe90fa4ca090b7cb253edd9a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1a3fb19830d4945aa9bddcc56e85cb4",
            "max": 578,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc930a6fd6ef4773b00050e3c11de5bf",
            "value": 578
          }
        },
        "de9a8f73143042bc83fee982088b790c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecfc99d4096446edbd9673a35b2d69b0",
            "placeholder": "​",
            "style": "IPY_MODEL_ac84e908ab054b39af768b3c433b8818",
            "value": " 578/578 [00:00&lt;00:00, 57.6kB/s]"
          }
        },
        "9cf04bb59d224835abe81441c429cc99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f655166a00e49d79cdfca6ae664859a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59b8e8f1de1f41f687268a3f9d24c199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1a3fb19830d4945aa9bddcc56e85cb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc930a6fd6ef4773b00050e3c11de5bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecfc99d4096446edbd9673a35b2d69b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac84e908ab054b39af768b3c433b8818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwengr/KoDeBERTa/blob/main/example/kodeberta_mlm_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNoALBeUZw6q",
        "outputId": "9759ee09-c02e-49bf-ce6b-2c06b426fd80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPUGuRwYZXrC",
        "outputId": "4492b5b8-d250-4f18-c82e-2cc0fa4aceb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/KoDeBERTa\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/KoDeBERTa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jwengr/KoDeBERTa.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4ITMeoLaJP2",
        "outputId": "d48cd560-64c3-4492-ee73-4167a918b34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KoDeBERTa'...\n",
            "remote: Enumerating objects: 56, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 56 (delta 16), reused 49 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (56/56), 60.72 KiB | 101.00 KiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.version.cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3HxXQIjsfF8g",
        "outputId": "fb753433-fb41-4b28-bb12-3a070ee970f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'11.8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --quiet cloud-tpu-client==0.10 torchvision==0.15.1+cu118 torch==2.0.0+cu118 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl -f https://download.pytorch.org/whl/cu118/torch_stable.html --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDacqvwSfLrk",
        "outputId": "19530ea2-8e5a-4e69-9188-30801070bb53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.9/162.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m948.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.2/120.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.1/138.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.6/123.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.0/157.0 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.7 requires jax>=0.4.6, but you have jax 0.3.25 which is incompatible.\n",
            "earthengine-api 0.1.350 requires google-api-python-client>=1.12.1, but you have google-api-python-client 1.8.0 which is incompatible.\n",
            "flax 0.6.9 requires jax>=0.4.2, but you have jax 0.3.25 which is incompatible.\n",
            "google-colab 1.0.0 requires google-auth==2.17.3, but you have google-auth 2.20.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.3 which is incompatible.\n",
            "orbax-checkpoint 0.2.1 requires jax>=0.4.8, but you have jax 0.3.25 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.3 which is incompatible.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 2.0.0+cu118 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 2.0.0+cu118 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 2.0.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pytorch-lightning transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so9yQG3Ud95V",
        "outputId": "994015f2-0c93-4dc9-a839-2fd133a2da10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.0.3-py3-none-any.whl (720 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.6/720.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.0.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.4.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.6.3)\n",
            "Collecting lightning-utilities>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from datasets)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.26.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.5.post0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: tokenizers, safetensors, xxhash, multidict, lightning-utilities, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets, torchmetrics, pytorch-lightning\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.15.1 lightning-utilities-0.8.0 multidict-6.0.4 multiprocess-0.70.14 pytorch-lightning-2.0.3 responses-0.18.0 safetensors-0.3.1 tokenizers-0.13.3 torchmetrics-0.11.4 transformers-4.30.2 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "\n",
        "sys.path.append(\"/content/drive/MyDrive/KoDeBERTa/KoDeBERTa/Model\")\n",
        "sys.path.append(\"/content/drive/MyDrive/KoDeBERTa/KoDeBERTa/Data\")"
      ],
      "metadata": {
        "id": "QYokXKGDbafy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from datasets import IterableDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "import DebertaV3\n",
        "import DataCollator"
      ],
      "metadata": {
        "id": "DODvKjzaaTmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gzip -d \"./data/mecab.txt.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WUkOOUvoQuO",
        "outputId": "0fb346bd-7e02-4875-c404-1361c8b7f3d3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED=0\n",
        "pl.seed_everything(SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lFgiQjVa8wZ",
        "outputId": "c550a79a-d8d5-4f8b-e29a-b362acc1c75c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer.from_file('./tokenizers/mecab-hf-unigram-880M-128k.json')"
      ],
      "metadata": {
        "id": "raC424gUjXYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_id = tokenizer.get_vocab()['[MASK]']\n",
        "pad_id = tokenizer.get_vocab()['[PAD]']"
      ],
      "metadata": {
        "id": "p31pjfwljbQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen():\n",
        "    with gzip.open('.data/mecab.txt.gz', encoding='utf-8-sig') as f:\n",
        "        for line in f:\n",
        "            yield line"
      ],
      "metadata": {
        "id": "b0xGIfffjcpy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8*24\n",
        "max_steps = 500_000 * (8192//batch_size)"
      ],
      "metadata": {
        "id": "WzqKKL8GkVhF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = IterableDataset.from_generator(gen)\n",
        "ds.__len__ = 880_000_000\n",
        "ds.shuffle(seed=SEED, buffer_size=8_800_000)\n",
        "dl = DataLoader(ds, batch_size=batch_size, collate_fn=DataCollator.DataCollatorForSentencePieceSpanMLM(tokenizer, truncation_argument={'max_length':512}))"
      ],
      "metadata": {
        "id": "EPTVc6mwki08"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "debertav3_pretrainer = DebertaV3.DebertaV3ForPretraining('microsoft/deberta-v3-xsmall', mask_id=mask_id, pad_id=pad_id, lr=1e-7, num_warmup_steps=int(max_steps*0.08), num_training_steps=max_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "dfb46f527ce94159b8c942d0963993cb",
            "f3fbd6c7c70e4810a8fc92e38e479d0c",
            "9e7eeffe90fa4ca090b7cb253edd9a6d",
            "de9a8f73143042bc83fee982088b790c",
            "9cf04bb59d224835abe81441c429cc99",
            "8f655166a00e49d79cdfca6ae664859a",
            "59b8e8f1de1f41f687268a3f9d24c199",
            "e1a3fb19830d4945aa9bddcc56e85cb4",
            "fc930a6fd6ef4773b00050e3c11de5bf",
            "ecfc99d4096446edbd9673a35b2d69b0",
            "ac84e908ab054b39af768b3c433b8818"
          ]
        },
        "id": "MmesJuAhkrgl",
        "outputId": "492a9743-2fbe-42fa-f9b1-7450deb58443"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfb46f527ce94159b8c942d0963993cb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='Loss_D',\n",
        "    dirpath='./model/',\n",
        "    filename='{epoch:02d}-{Loss_G:.4f}-{Loss_D:.4f}',\n",
        "    save_weights_only=True,\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    accelerator='tpu',\n",
        "    devices=8,\n",
        "    precision='bf16-mixed',\n",
        "    max_steps=max_steps,\n",
        "    callbacks=[checkpoint_callback],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUaTcGpbkvT7",
        "outputId": "fd81469e-7d47-4a02-fe56-74b632d59217"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightning_fabric/connector.py:555: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:488: UserWarning: You passed `Trainer(accelerator='tpu', precision='16-mixed')` but AMP with fp16 is not supported on TPUs. Using `precision='bf16-mixed'` instead.\n",
            "  rank_zero_warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: True, using: 8 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(debertav3_pretrainer,dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dG_rlX83lmU4",
        "outputId": "ca347201-e630-45c4-cf28-9a7df6e804ef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name          | Type                            | Params\n",
            "------------------------------------------------------------------\n",
            "0 | generator     | DebertaV2ForMaskedLM            | 60.3 M\n",
            "1 | discriminator | DebertaV2ForTokenClassification | 119 M \n",
            "------------------------------------------------------------------\n",
            "180 M     Trainable params\n",
            "0         Non-trainable params\n",
            "180 M     Total params\n",
            "720.741   Total estimated model params size (MB)\n",
            "Exception in device=TPU:0: TPUs do not currently support IterableDataset objects, the dataset must implement `__len__`. HINT: You can mock the length on your dataset to bypass this error.Exception in device=TPU:4: TPUs do not currently support IterableDataset objects, the dataset must implement `__len__`. HINT: You can mock the length on your dataset to bypass this error.Exception in device=TPU:3: TPUs do not currently support IterableDataset objects, the dataset must implement `__len__`. HINT: You can mock the length on your dataset to bypass this error.Exception in device=TPU:6: TPUs do not currently support IterableDataset objects, the dataset must implement `__len__`. HINT: You can mock the length on your dataset to bypass this error.Exception in device=TPU:5: TPUs do not currently support IterableDataset objects, the dataset must implement `__len__`. HINT: You can mock the length on your dataset to bypass this error.Exception in device=TPU:7: TPUs do not currently support IterableDataset objects, the dataset must implement `__len__`. HINT: You can mock the length on your dataset to bypass this error.Exception in device=TPU:2: TPUs do not currently support IterableDataset objects, the dataset must implement `__len__`. HINT: You can mock the length on your dataset to bypass this error.Exception in device=TPU:1: TPUs do not currently support IterableDataset objects, the dataset must implement `__len__`. HINT: You can mock the length on your dataset to bypass this error.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 334, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 334, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 334, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 334, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 334, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 334, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 328, in _start_fn\n",
            "    fn(gindex, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 334, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 328, in _start_fn\n",
            "    fn(gindex, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 328, in _start_fn\n",
            "    fn(gindex, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 334, in _mp_start_fn\n",
            "    _start_fn(index, pf_cfg, fn, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 328, in _start_fn\n",
            "    fn(gindex, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 328, in _start_fn\n",
            "    fn(gindex, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 328, in _start_fn\n",
            "    fn(gindex, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/launchers/xla.py\", line 107, in _wrapping_function\n",
            "    results = function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 328, in _start_fn\n",
            "    fn(gindex, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/launchers/xla.py\", line 107, in _wrapping_function\n",
            "    results = function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 328, in _start_fn\n",
            "    fn(gindex, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/launchers/xla.py\", line 107, in _wrapping_function\n",
            "    results = function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/launchers/xla.py\", line 107, in _wrapping_function\n",
            "    results = function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/launchers/xla.py\", line 107, in _wrapping_function\n",
            "    results = function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/launchers/xla.py\", line 107, in _wrapping_function\n",
            "    results = function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 570, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/launchers/xla.py\", line 107, in _wrapping_function\n",
            "    results = function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 570, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/launchers/xla.py\", line 107, in _wrapping_function\n",
            "    results = function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 570, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 570, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 570, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 570, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 570, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 975, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 975, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 570, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 975, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 975, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 975, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 975, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 975, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1018, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1018, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 975, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1018, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1018, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1018, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 193, in run\n",
            "    self.setup_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1018, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1018, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 193, in run\n",
            "    self.setup_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1018, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 193, in run\n",
            "    self.setup_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 193, in run\n",
            "    self.setup_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 193, in run\n",
            "    self.setup_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 236, in setup_data\n",
            "    dl = _process_dataloader(trainer, dl)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 193, in run\n",
            "    self.setup_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 236, in setup_data\n",
            "    dl = _process_dataloader(trainer, dl)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 193, in run\n",
            "    self.setup_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 193, in run\n",
            "    self.setup_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 236, in setup_data\n",
            "    dl = _process_dataloader(trainer, dl)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 236, in setup_data\n",
            "    dl = _process_dataloader(trainer, dl)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 236, in setup_data\n",
            "    dl = _process_dataloader(trainer, dl)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 236, in setup_data\n",
            "    dl = _process_dataloader(trainer, dl)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 493, in _process_dataloader\n",
            "    dataloader = strategy.process_dataloader(dataloader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 493, in _process_dataloader\n",
            "    dataloader = strategy.process_dataloader(dataloader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 236, in setup_data\n",
            "    dl = _process_dataloader(trainer, dl)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 236, in setup_data\n",
            "    dl = _process_dataloader(trainer, dl)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 493, in _process_dataloader\n",
            "    dataloader = strategy.process_dataloader(dataloader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 493, in _process_dataloader\n",
            "    dataloader = strategy.process_dataloader(dataloader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 493, in _process_dataloader\n",
            "    dataloader = strategy.process_dataloader(dataloader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/xla.py\", line 151, in process_dataloader\n",
            "    XLAStrategy._validate_dataloader(dataloader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 493, in _process_dataloader\n",
            "    dataloader = strategy.process_dataloader(dataloader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/xla.py\", line 151, in process_dataloader\n",
            "    XLAStrategy._validate_dataloader(dataloader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 493, in _process_dataloader\n",
            "    dataloader = strategy.process_dataloader(dataloader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 493, in _process_dataloader\n",
            "    dataloader = strategy.process_dataloader(dataloader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/xla.py\", line 151, in process_dataloader\n",
            "    XLAStrategy._validate_dataloader(dataloader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/xla.py\", line 151, in process_dataloader\n",
            "    XLAStrategy._validate_dataloader(dataloader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/xla.py\", line 151, in process_dataloader\n",
            "    XLAStrategy._validate_dataloader(dataloader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/xla.py\", line 104, in _validate_dataloader\n",
            "    raise TypeError(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/xla.py\", line 151, in process_dataloader\n",
            "    XLAStrategy._validate_dataloader(dataloader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/xla.py\", line 104, in _validate_dataloader\n",
            "    raise TypeError(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/xla.py\", line 151, in process_dataloader\n",
            "    XLAStrategy._validate_dataloader(dataloader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/xla.py\", line 151, in process_dataloader\n",
            "    XLAStrategy._validate_dataloader(dataloader)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/xla.py\", line 104, in _validate_dataloader\n",
            "    raise TypeError(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/xla.py\", line 104, in _validate_dataloader\n",
            "    raise TypeError(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/xla.py\", line 104, in _validate_dataloader\n",
            "    raise TypeError(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/xla.py\", line 104, in _validate_dataloader\n",
            "    raise TypeError(\n",
            "TypeError: TPUs do not currently support IterableDataset objects, the dataset must implement `__len__`. HINT: You can mock the length on your dataset to bypass this error.\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/xla.py\", line 104, in _validate_dataloader\n",
            "    raise TypeError(\n",
            "TypeError: TPUs do not currently support IterableDataset objects, the dataset must implement `__len__`. HINT: You can mock the length on your dataset to bypass this error.\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/xla.py\", line 104, in _validate_dataloader\n",
            "    raise TypeError(\n",
            "TypeError: TPUs do not currently support IterableDataset objects, the dataset must implement `__len__`. HINT: You can mock the length on your dataset to bypass this error.\n",
            "TypeError: TPUs do not currently support IterableDataset objects, the dataset must implement `__len__`. HINT: You can mock the length on your dataset to bypass this error.\n",
            "TypeError: TPUs do not currently support IterableDataset objects, the dataset must implement `__len__`. HINT: You can mock the length on your dataset to bypass this error.\n",
            "TypeError: TPUs do not currently support IterableDataset objects, the dataset must implement `__len__`. HINT: You can mock the length on your dataset to bypass this error.\n",
            "TypeError: TPUs do not currently support IterableDataset objects, the dataset must implement `__len__`. HINT: You can mock the length on your dataset to bypass this error.\n",
            "TypeError: TPUs do not currently support IterableDataset objects, the dataset must implement `__len__`. HINT: You can mock the length on your dataset to bypass this error.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ProcessExitedException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-9e10a6fff0b6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebertav3_pretrainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_unwrap_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/launchers/xla.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, function, trainer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprocess_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprocess_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 )\n\u001b[1;32m    148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 raise ProcessExitedException(\n\u001b[0m\u001b[1;32m    150\u001b[0m                     \u001b[0;34m\"process %d terminated with exit code %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mProcessExitedException\u001b[0m: process 4 terminated with exit code 17"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E98u_rU8lw-O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}