{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwengr/KoDeBERTa/blob/main/colab_tpu_tf_profiling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "xcyT8otlajMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/KoDeBERTa/KoDeBERTa"
      ],
      "metadata": {
        "id": "g8b0I-q4alRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zxx_mPlE-saf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "IS_COLAB_BACKEND = 'COLAB_GPU' in os.environ  # this is always set on Colab, the value is 0 or 1 depending on GPU presence\n",
        "if IS_COLAB_BACKEND:\n",
        "  from google.colab import auth\n",
        "  # Authenticates the Colab machine and also the TPU using your\n",
        "  # credentials so that they can access your private GCS buckets.\n",
        "  auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZXJSIYyUMa1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6663ab0-9250-4cbc-e0fc-fb7e98cafeae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting install\n",
            "  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\n",
            "Collecting tensorboard_plugin_profile==2.3.0\n",
            "  Downloading tensorboard_plugin_profile-2.3.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gviz-api>=1.9.0 (from tensorboard_plugin_profile==2.3.0)\n",
            "  Downloading gviz_api-1.10.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard_plugin_profile==2.3.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard_plugin_profile==2.3.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard_plugin_profile==2.3.0) (1.16.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard_plugin_profile==2.3.0) (2.3.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard_plugin_profile==2.3.0) (2.1.3)\n",
            "Installing collected packages: pip, install, gviz-api, tensorboard_plugin_profile\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed gviz-api-1.10.0 install-1.3.5 pip-23.2 tensorboard_plugin_profile-2.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet -U pip install -U tensorboard_plugin_profile==2.3.0 gcsfs datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FpvUOuC3j27n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d41bc32-4683-4c28-a027-86f05f96eadd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Tensorflow version 2.12.0\n",
            "Running on TPU  ['10.92.140.18:8470']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vFIMfPmgQa0h"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvPXiovhi3ZZ"
      },
      "source": [
        "\n",
        "## Input data\n",
        "\n",
        "Our input data is stored on Google Cloud Storage. To more fully use the parallelism TPUs offer us, and to avoid bottlenecking on data transfer, we've stored our input data in TFRecord files, 230 images per file.\n",
        "\n",
        "Below, we make heavy use of `tf.data.experimental.AUTOTUNE` to optimize different parts of input loading.\n",
        "\n",
        "All of these techniques are a bit overkill for our (small) dataset, but demonstrate best practices for using TPUs.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gcsfs\n",
        "\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "yqRRxMrlVvua"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "storage_options={\"project\": \"My Project 47552\"}"
      ],
      "metadata": {
        "id": "wQe_NGtvWTYi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fs = gcsfs.GCSFileSystem(**storage_options)"
      ],
      "metadata": {
        "id": "HMV02yyRWXCA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_paths = list(filter(lambda x: x[-4:] == '.txt', fs.ls('jinwoo0766/data')))\n",
        "data_paths = ['jinwoo0766/data/mecab-1.txt']"
      ],
      "metadata": {
        "id": "ltj1ByMLWYPt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen():\n",
        "    for data_path in data_paths:\n",
        "        with fs.open(data_path, encoding='utf-8-sig') as f:\n",
        "            for line in f:\n",
        "                yield {\"line\": line}"
      ],
      "metadata": {
        "id": "ajf0PxaOXpEG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset.from_generator(gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "9f403616ccb745f7a0fd69012207c54f",
            "d346ca4e59164f46a4f024642a3bb43f",
            "03a3723022384bb1b041993d34929091",
            "ad27b0e31d694b5897ce5f54e9191407",
            "d1b8b6d76393415396ec23465bcba9d1",
            "fb25684de0d44309b0ab3e3265dc3339",
            "b9de826cd14340ac8690b26fad92b16c",
            "f89cde8fc78f4fdaa115043e8306c338",
            "dfe05846a7e54ad8ba8bf2c95963a433",
            "23a413211b18416ead2d564e2dcc6c09",
            "47c8ffc0d40242238e681ffaa8f7b861"
          ]
        },
        "id": "10e1zP0RYFbm",
        "outputId": "a52a8045-4681-4d39-910d-d6547be1af50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset generator/default to /root/.cache/huggingface/datasets/generator/default-5f581f2563ac5b2f/0.0.0...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f403616ccb745f7a0fd69012207c54f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.to_tf_dataset(\n",
        "    collate_fn=\n",
        "    batch_size=8\n",
        ")"
      ],
      "metadata": {
        "id": "kOo202SeaLNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtAVr-4CP1rp"
      },
      "outputs": [],
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "IMAGE_SIZE = [331, 331]\n",
        "\n",
        "batch_size = 16 * tpu_strategy.num_replicas_in_sync\n",
        "\n",
        "gcs_pattern = 'gs://flowers-public/tfrecords-jpeg-331x331/*.tfrec'\n",
        "validation_split = 0.19\n",
        "filenames = tf.io.gfile.glob(gcs_pattern)\n",
        "split = len(filenames) - int(len(filenames) * validation_split)\n",
        "train_fns = filenames[:split]\n",
        "validation_fns = filenames[split:]\n",
        "\n",
        "def parse_tfrecord(example):\n",
        "  features = {\n",
        "    \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
        "    \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means scalar\n",
        "    \"one_hot_class\": tf.io.VarLenFeature(tf.float32),\n",
        "  }\n",
        "  example = tf.io.parse_single_example(example, features)\n",
        "  decoded = tf.image.decode_jpeg(example['image'], channels=3)\n",
        "  normalized = tf.cast(decoded, tf.float32) / 255.0 # convert each 0-255 value to floats in [0, 1] range\n",
        "  image_tensor = tf.reshape(normalized, [*IMAGE_SIZE, 3])\n",
        "  one_hot_class = tf.reshape(tf.sparse.to_dense(example['one_hot_class']), [5])\n",
        "  return image_tensor, one_hot_class\n",
        "\n",
        "def load_dataset(filenames):\n",
        "  # Read from TFRecords. For optimal performance, we interleave reads from multiple files.\n",
        "  records = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "  return records.map(parse_tfrecord, num_parallel_calls=AUTO)\n",
        "\n",
        "def get_training_dataset():\n",
        "  dataset = load_dataset(train_fns)\n",
        "\n",
        "  # Create some additional training images by randomly flipping and\n",
        "  # increasing/decreasing the saturation of images in the training set.\n",
        "  def data_augment(image, one_hot_class):\n",
        "    modified = tf.image.random_flip_left_right(image)\n",
        "    modified = tf.image.random_saturation(modified, 0, 2)\n",
        "    return modified, one_hot_class\n",
        "  augmented = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
        "\n",
        "  # Prefetch the next batch while training (autotune prefetch buffer size).\n",
        "  return augmented.repeat().shuffle(2048).batch(batch_size).prefetch(AUTO)\n",
        "\n",
        "training_dataset = get_training_dataset()\n",
        "validation_dataset = load_dataset(validation_fns).batch(batch_size).prefetch(AUTO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTukaIGil7_m"
      },
      "source": [
        "Let's take a peek at the training dataset we've created:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DwfsJq0l_DJ"
      },
      "outputs": [],
      "source": [
        "CLASSES = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
        "\n",
        "def display_one_flower(image, title, subplot, color):\n",
        "  plt.subplot(subplot)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(image)\n",
        "  plt.title(title, fontsize=16, color=color)\n",
        "\n",
        "# If model is provided, use it to generate predictions.\n",
        "def display_nine_flowers(images, titles, title_colors=None):\n",
        "  subplot = 331\n",
        "  plt.figure(figsize=(13,13))\n",
        "  for i in range(9):\n",
        "    color = 'black' if title_colors is None else title_colors[i]\n",
        "    display_one_flower(images[i], titles[i], 331+i, color)\n",
        "  plt.tight_layout()\n",
        "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "  plt.show()\n",
        "\n",
        "def get_dataset_iterator(dataset, n_examples):\n",
        "  return dataset.unbatch().batch(n_examples).as_numpy_iterator()\n",
        "\n",
        "training_viz_iterator = get_dataset_iterator(training_dataset, 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTnyd7qfbYr4"
      },
      "outputs": [],
      "source": [
        "# Re-run this cell to show a new batch of images\n",
        "images, classes = next(training_viz_iterator)\n",
        "class_idxs = np.argmax(classes, axis=-1) # transform from one-hot array to class number\n",
        "labels = [CLASSES[idx] for idx in class_idxs]\n",
        "display_nine_flowers(images, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALtRUlxhw8Vt"
      },
      "source": [
        "## Model\n",
        "To get maxmimum accuracy, we leverage a pretrained image recognition model (here, [Xception](http://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf)). We drop the ImageNet-specific top layers (`include_top=false`), and add a max pooling and a softmax layer to predict our 5 classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJl3vNtJOB-x"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  pretrained_model = tf.keras.applications.Xception(input_shape=[*IMAGE_SIZE, 3], include_top=False)\n",
        "  pretrained_model.trainable = True\n",
        "  model = tf.keras.Sequential([\n",
        "    pretrained_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "  ])\n",
        "  model.compile(\n",
        "    optimizer='adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "  return model\n",
        "\n",
        "with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "  model = create_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMfenMQcxAAb"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0wDLhZOdjAA"
      },
      "source": [
        "Calculate the number of images in each dataset. Rather than actually load the data to do so (expensive), we rely on hints in the filename. This is used to calculate the number of batches per epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-ID7vP5mIKs"
      },
      "outputs": [],
      "source": [
        "def count_data_items(filenames):\n",
        "  # The number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
        "  n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "  return np.sum(n)\n",
        "\n",
        "n_train = count_data_items(train_fns)\n",
        "n_valid = count_data_items(validation_fns)\n",
        "train_steps = count_data_items(train_fns) // batch_size\n",
        "print(\"TRAINING IMAGES: \", n_train, \", STEPS PER EPOCH: \", train_steps)\n",
        "print(\"VALIDATION IMAGES: \", n_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqYT2OcmdnBu"
      },
      "source": [
        "Calculate and show a learning rate schedule. We start with a fairly low rate, as we're using a pre-trained model and don't want to undo all the fine work put into training it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXJXG-Ufdbnu"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 12\n",
        "\n",
        "start_lr = 0.00001\n",
        "min_lr = 0.00001\n",
        "max_lr = 0.00005 * tpu_strategy.num_replicas_in_sync\n",
        "rampup_epochs = 5\n",
        "sustain_epochs = 0\n",
        "exp_decay = .8\n",
        "\n",
        "def lrfn(epoch):\n",
        "  if epoch < rampup_epochs:\n",
        "    return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n",
        "  elif epoch < rampup_epochs + sustain_epochs:\n",
        "    return max_lr\n",
        "  else:\n",
        "    return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n",
        "\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=True)\n",
        "\n",
        "rang = np.arange(EPOCHS)\n",
        "y = [lrfn(x) for x in rang]\n",
        "plt.plot(rang, y)\n",
        "print('Learning rate per epoch:')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs2tsV8xebhU"
      },
      "source": [
        "Train the model. While the first epoch will be quite a bit slower as we must XLA-compile the execution graph and load the data, later epochs should complete in ~5s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsxeGPJeyb5v"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTrfSGu38TLd"
      },
      "outputs": [],
      "source": [
        "# Get TPU profiling service address. This address will be needed for capturing\n",
        "# profile information with TensorBoard in the following steps.\n",
        "service_addr = tpu.get_master().replace(':8470', ':8466')\n",
        "print(service_addr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNA__vniyY8e"
      },
      "outputs": [],
      "source": [
        "# Launch TensorBoard.\n",
        "%tensorboard --logdir=gs://bucket-name  # Replace the bucket-name variable with your own gcs bucket"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erj2-mPpvqbG"
      },
      "source": [
        "The TensorBoard UI is displayed in a browser window. In this colab, perform the following steps to prepare to capture profile information.\n",
        "1.  Click on the dropdown menu box on the top right side and scroll down and click PROFILE. A new window appears that shows: **No profile data was found** at the top.\n",
        "1.  Click on the CAPTURE PROFILE button. A new dialog appears. The top input line shows: **Profile Service URL or TPU name**. Copy and paste the Profile Service URL (the service_addr value shown before launching TensorBoard) into the top input line. While still on the dialog box, start the training with the next step.\n",
        "1.  Click on the next colab cell to start training the model.\n",
        "1.  Watch the output from the training until several epochs have completed. This allows time for the profile data to start being collected. Return to the dialog box and click on the CAPTURE button. If the capture succeeds, the page will auto refresh and redirect you to the profiling results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Qv8rC4aVOFB"
      },
      "outputs": [],
      "source": [
        "history = model.fit(training_dataset, validation_data=validation_dataset,\n",
        "                    steps_per_epoch=train_steps, epochs=EPOCHS, callbacks=[lr_callback])\n",
        "\n",
        "final_accuracy = history.history[\"val_accuracy\"][-5:]\n",
        "print(\"FINAL ACCURACY MEAN-5: \", np.mean(final_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VngeUBIdyJ1T"
      },
      "outputs": [],
      "source": [
        "def display_training_curves(training, validation, title, subplot):\n",
        "  ax = plt.subplot(subplot)\n",
        "  ax.plot(training)\n",
        "  ax.plot(validation)\n",
        "  ax.set_title('model '+ title)\n",
        "  ax.set_ylabel(title)\n",
        "  ax.set_xlabel('epoch')\n",
        "  ax.legend(['training', 'validation'])\n",
        "\n",
        "plt.subplots(figsize=(10,10))\n",
        "plt.tight_layout()\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 211)\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o19yp4TxqmgI"
      },
      "source": [
        "Accuracy goes up and loss goes down. Looks good!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_rjVo-RAoYd"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "More TPU/Keras examples include:\n",
        "- [Shakespeare in 5 minutes with Cloud TPUs and Keras](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/shakespeare_with_tpu_and_keras.ipynb)\n",
        "- [Fashion MNIST with Keras and TPUs](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/fashion_mnist.ipynb)\n",
        "\n",
        "We'll be sharing more examples of TPU use in Colab over time, so be sure to check back for additional example links, or [follow us on Twitter @GoogleColab](https://twitter.com/googlecolab)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f403616ccb745f7a0fd69012207c54f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d346ca4e59164f46a4f024642a3bb43f",
              "IPY_MODEL_03a3723022384bb1b041993d34929091",
              "IPY_MODEL_ad27b0e31d694b5897ce5f54e9191407"
            ],
            "layout": "IPY_MODEL_d1b8b6d76393415396ec23465bcba9d1"
          }
        },
        "d346ca4e59164f46a4f024642a3bb43f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb25684de0d44309b0ab3e3265dc3339",
            "placeholder": "​",
            "style": "IPY_MODEL_b9de826cd14340ac8690b26fad92b16c",
            "value": "Generating train split: "
          }
        },
        "03a3723022384bb1b041993d34929091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f89cde8fc78f4fdaa115043e8306c338",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfe05846a7e54ad8ba8bf2c95963a433",
            "value": 1
          }
        },
        "ad27b0e31d694b5897ce5f54e9191407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23a413211b18416ead2d564e2dcc6c09",
            "placeholder": "​",
            "style": "IPY_MODEL_47c8ffc0d40242238e681ffaa8f7b861",
            "value": " 694100/0 [08:04&lt;00:00, 1568.62 examples/s]"
          }
        },
        "d1b8b6d76393415396ec23465bcba9d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb25684de0d44309b0ab3e3265dc3339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9de826cd14340ac8690b26fad92b16c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f89cde8fc78f4fdaa115043e8306c338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "dfe05846a7e54ad8ba8bf2c95963a433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23a413211b18416ead2d564e2dcc6c09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47c8ffc0d40242238e681ffaa8f7b861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}