{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import \n",
    "\n",
    "\n",
    "sys.path.append('C:/Users/dust/Documents/Github/KorDeBERTa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from datasets import IterableDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from Data.DataCollator import DataCollatorForSentencePieceSpanMLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file('../.local/tokenizers/mecab-hf-unigram-880M-128k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen():\n",
    "    with open('../../../Preproc5/korean/mecab.txt', encoding='utf-8-sig') as f:\n",
    "        for line in f:\n",
    "            yield line\n",
    "        raise StopIteration\n",
    "ds = IterableDataset.from_generator(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, collate_fn=DataCollatorForSentencePieceSpanMLM(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁한국', '▁미국', '▁', '캐나다', '▁', '호', '주', '▁', '등', '▁', '전', '▁세계', '▁', '3', '2', '▁', '개', '국', '▁', '7', '5', '▁', '여', '▁', '명', '▁', '의', '▁', '대학생', '▁', ',', '▁', '청소년', '▁', '들', '▁', '이', '▁', '모', '여', '▁', '전', '▁세계', '▁', '적', '▁', '현', '안', '▁문제', '▁', '에', '▁대한', '▁', '대', '안', '▁', '과', '▁', '해', '결', '책', '▁', '을', '▁', '모', '색', '▁', '하', '▁', '는', '▁', '자', '리', '▁', '다', '▁', '.']\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'mask_flag' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m dl:\n\u001b[0;32m      2\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dust\\.virtualenvs\\KorDeBERTa-GOeAzVPe\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\dust\\.virtualenvs\\KorDeBERTa-GOeAzVPe\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\dust\\.virtualenvs\\KorDeBERTa-GOeAzVPe\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:42\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_iter)\n\u001b[1;32m---> 42\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mC:\\Users/dust/Documents/Github/KorDeBERTa\\Data\\DataCollator.py:46\u001b[0m, in \u001b[0;36mDataCollatorForSentencePieceSpanMLM.__call__\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m     44\u001b[0m label_id \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(encode\u001b[39m.\u001b[39mids)\n\u001b[0;32m     45\u001b[0m label_ids\u001b[39m.\u001b[39mappend(label_id)\n\u001b[1;32m---> 46\u001b[0m masked_id \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_span_mlm(encode\u001b[39m.\u001b[39;49mids))\n\u001b[0;32m     47\u001b[0m masked_ids\u001b[39m.\u001b[39mappend(masked_id)\n\u001b[0;32m     48\u001b[0m attention_masks\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mLongTensor(encode\u001b[39m.\u001b[39mattention_mask))\n",
      "File \u001b[1;32mC:\\Users/dust/Documents/Github/KorDeBERTa\\Data\\DataCollator.py:72\u001b[0m, in \u001b[0;36mDataCollatorForSentencePieceSpanMLM._span_mlm\u001b[1;34m(self, encode_ids)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     \u001b[39mif\u001b[39;00m mask_flag:\n\u001b[0;32m     73\u001b[0m         encode_ids_mlm\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmask_id)\n\u001b[0;32m     74\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'mask_flag' referenced before assignment"
     ]
    }
   ],
   "source": [
    "for batch in dl:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_mlm_collator = DataCollatorForSpanMLM(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [{'text':'이것은 collator fn 테스트 실험입니다.'},{'text':'에러없이 잘 진행되면 좋겠군요 부탁드립니다.'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    7,     9,    45,    19,     7, 35800, 21464, 12742,     7,     6,\n",
      "            6,     6,     7,     8,     1,     1,     1,     1])\n",
      "tensor([   6,   16,  261,   74,    9,    7,  192,  436,   58,   50,    7,  171,\n",
      "         120, 1971,    7, 5221,    7,    8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label_ids': tensor([[    7,     9,    45,    19,     7, 35800, 21464, 12742,     7,  1907,\n",
       "           1496,   217,     7,     8,     1,     1,     1,     1],\n",
       "         [    7,    16,   261,    74,     9,     7,   192,   436,    58,    50,\n",
       "              7,   171,   120,  1971,     7,  5221,     7,     8]]),\n",
       " 'masked_texts': tensor([[    7,     9,    45,    19,     7, 35800, 21464, 12742,     7,     6,\n",
       "              6,     6,     7,     8,     1,     1,     1,     1],\n",
       "         [    6,    16,   261,    74,     9,     7,   192,   436,    58,    50,\n",
       "              7,   171,   120,  1971,     7,  5221,     7,     8]]),\n",
       " 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_mlm_collator(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KorDeBERTa-GOeAzVPe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
